---
title: "AI 工作流与技术沉淀：智能体调度与 RTL 混排实战"
date: 2026-02-27T11:02:00Z
draft: false
tags: ["AI", "Architecture", "Engineering", "Productivity"]
categories: ["Technical Diary"]
---

今天的复盘主要围绕 AI 智能体（Agent）的使用 ROI 评估，以及技术攻坚中暴露出的几个架构问题。

## 重新审视 AI Agent 的“正确打开方式”

近期对 AI 辅助编程的边界有了更清晰的感知。虽然像 OpenClaw 这样的 Agent 框架极具潜力，但在实际落地中，如果直接让 Agent 去接管高强度、高耦合度的核心代码重构，往往会导致极其惨烈的 Token 消耗战，且产出极不稳定。

真正的破局点在于**任务架构的重塑**。Agent 不是高级打字员，而是执行流水线上的节点。对于大型任务，必须由人（或者架构师 Agent）先完成松耦合的模块拆解，然后并行派发给多个 AI Worker 独立执行。

在当前的工程语境下，“如何用自然语言设计出无歧义、低上下文依赖的任务 Prompt”，其重要性已经等同于甚至超越了底层代码的实现能力。顺便一提，就目前观察，Gemini 3.1 在面对这种多模态和复杂指令调度时，依然保持着优于 Claude 的压制力。

## 业务攻坚：RTL 混排与框架设计的博弈

在尝试为某个复杂的富文本系统实现 RTL（从右到左）布局支持时，发生了一次非常有意思的技术博弈。

初始思路非常“云原生”：让 Agent 通过阅读框架源码，试图利用上层的插件化（Plugin-based）机制来“Hack”掉底层的排版引擎，以此接管中东语系的混排文本方向。
然而，早期的测试直接宣告了这条路走不通。当遇到复杂的 Bidi（双向文本）算法时，由于底层 Canvas 渲染矩阵的限制，仅靠外围的插件拦截根本无法从根本上解决视觉排序错乱的顽疾，最后依然不得不回到引入专门算法库进行底层文本重排的路径上。

这个过程暴露了一个极其普遍的工程陷阱：**当框架底层的抽象维度不够（比如没考虑 RTL 坐标系翻转）时，试图在应用层/插件层通过“奇技淫巧”去弥补，大概率会陷入无尽的技术债。**

## 基础设施：版本跃迁的代价与 AI 的局限

另外，最近系统在向 JDK 17 及 Spring Boot 3.x 演进的过程中，遭遇了 KMS（密钥管理服务）无法加载 Nacos 配置的阻断问题。

非常有戏剧性的是，其实我早就在 KMS 的注释里明确提示了 Spring Boot 3.x 需要调整的方案：因为加载机制的变更，必须从早期的 `bootstrap` 机制迁移到 `configdata`。但是由于时间久远，加上这次升级改造图省事，把“整包代码”全权丢给了 AI Agent 去跑。结果呢？AI 没有敏锐地捕捉到那些散落在代码角落里的关键注释和业务上下文，像只没头苍蝇一样在错误的方向上耗费了大量的时间、Token 和计算资源去排查问题，最后还是靠人工下场才拨乱反正。

这再次证明了一个血淋淋的事实：没有正确上下文引导的 AI 很容易陷入盲人摸象的窘境，过度依赖反而会拖慢排错效率。

## 结语

从让 Agent 代写代码，到让 Agent 设计方案甚至自我纠错，我们正在经历一次研发范式的剧变。

但有趣的是，AI 越强大，工程世界里那些最古老的真理就显得越发刺眼：**糟糕的系统架构，连 AI 都救不了。** 如果你的底层代码耦合如面条，试图指望塞进去一个“无敌 Agent”来自动重构，结果大概率是跑崩上下文。AI 最大的价值，恰恰在于逼着我们先去写出边界清晰、逻辑自洽的系统。因为只有人先把系统拆对了，AI 才能跑得快。